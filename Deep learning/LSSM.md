# BUG 
1. V4版本 预测值全变成了0  
	解决：清梯度，损失函数有问题，修改了损失函数，增加了清缓存
# ST
##  版本迭代
1. 103041 dims 64 batchsize 128 v5 改了lap的融合方式，没改LN和DDB卷积，AFF激活
	1.F1 81 到第24轮之后就不涨了
2. 103140 跟10341版本一样，lr提升了10.7倍，再跑一次
	1. F1 8968 推理F1 1024 9033得分全比ChangeMamba大 比在自己电脑上跑出的效果好
	2. 学习率在倒数第二轮才发生变化，所以把轮数拉高到300再跑
3. 103144 1485 v6 batchsize 12 epoch200  
	1. 时间变得特别长 跑了18个点
	2. 得分下降了，意思AFF的激活换拉了 45轮就停了 8857
4. 103145 1577 v6 batchsize 128 lr 0.00107 
	1. F1 8921 39轮就不涨了
5. 103165 1486 v5 300轮 
	1. 仍然是8956
6. 103248 v5 1486 lr0.0008 epoch 150
7.  √103255 v6 AFF tanh lr 0.0008 epoch 150
8. 103257 v6 AFF GELU lr 0.0008 epoch 150
9. 103502 1577 v8.1 再训练一次，我觉得是训练的问题
	1. 103578再跑一次，没变
	2. 把三个张量cat到一起可能造成了信息丢失
10. 103503 1485 v6.2 的 DDB改回来了 得分下降一点
11. 103514 1486 v8.2
12. 103635 1485 v8.3 看看融合方式换成
13. 103642 1577 v9 work
14. 103797 1577 v9 把c跟out相加的去掉了 best
15. 103803 1485 v10 2 2 10 显存跑满了
16. 103804 1486 v10 2 2 8 把超算显存跑满了
17. 103857 1486 v10 2 2 15 换回64 还是把显存爆了
18. 103858 1485 v10 2 2 8 64 能跑
19. 103892 1486 v10 2 2 10 64 
接下来的工作：
 1. Adam修改成AdamW 引入5e-4
 2. 再考虑增强的方式，确保增强信息所占总信息的比重是合适的
3. 修改DDB
	1. 看相加好还是cat好
	2. gelu没必要加吧
	3. ffn加不加感觉没必要
4. 卷积核设置成3*3的
5. 103803和103804把超算直接跑满了
	1. 报错
		1. 位置不同，都在解码层，一个vssb1一个2
	2. 但参数量并没有很大
		1. 才30多M
		2. 并且在笔记本上是能跑的，用12bs，但是跑的极其慢
	3. 现状，即便改成64的，15层也会把显存跑满
6. 把算子方法增强
	1. 找算子方法的薄弱处（问ai，看其他用laplace的论文
	2. 找算子的作用机理，然后补足
		1. Laplace好像是对二阶变化比较敏感，然后给他再补足一个一阶？应该分析遥感图像边缘的特征，是不是在一阶和二阶变化上有什么特性
			laplace关注二阶变化
	3. 边缘特征所具有的特性：
		1. 线性边缘
		2. 噪声
			1. 能不能具体到非建筑噪声，非建筑噪声都具有非线性性.
				1. EAD引入四向三层的sobel结构提取线性边缘特征，然后通过卷积操作说融合并抑制噪声
				2. 
		

也就是如果通过算子捕捉到线性或者非线性
## 消融
1. 拿掉融合分支,也就是单独把主干拎出来
	1. 填上头
		1. 现有：对AB融合后经过核心
		2. 要对比：
			1. A,B分别进入共享核心
			2. A,B分别进入不共享核心
			都进入共享的AB后融合模块，
		
	2. BN和LN对比
	3. 修改跳接方式
		1. 直接cat
		2. 用senet
		3. 不跳接 
	要去掉的东西：
		1. 编码层：DDB
		2. 解码层：整个增强分支
1.  v1 干净的主干 和 带上头的对比

主线，执行VSS  
当AFF为None时，就是解码层第一层，主线和分支都用ABfuse,若不为None，主线用上一层的AFF结果，分支用ABfuse  
  
原本的设计中，当经过第一层解码层后，传入vssb的就是aff后的结果，不再与AB进行跳接，跳接就单独放在Laplce中，Laplace将通道数压到了1，特征信息变少了  
跳接的设计不能丢，跳接应该保留在主干网络中  
AFF,A,B如何融合，  
 1.能不能把AFF拓展到三个融合  
 2.看看其他网络跳接是怎么处理的  
     AERNET就是单纯的cat然后归一激活甚至就一轮，融合之后跟解码层核心处理完后再一个跳接  
     ConMamba不带跳接  
     changemamba中引入三个vssb处理  
  把A,B,AFFOUT，融合经过VSSB和AFFOUT经过VSSB然后跟AB融合进行对比

# Version
## Version1
1. 训练到49轮左右时lr迭代到了1e-5，得分提升了  
2. 又开了新一轮，直接把lr设定为1e-5，并且把迭代频率考察epoch数从15换成了10，得分再也提不动了  
3. 疑似10轮太少了，导致学习率拼命减，减过头更新不动了
## Version2
1. 将dim从64改成96开始  
	参数量直接从37 干到77  
	训练速度从1.5s左右干到15s左右  
	从不到十分钟干到仨小时  
1. dim改成80  
	参数量53  
	训练速度5s 一轮一小时 训练不动没训练
## Version3
1. 修改所有降通道操作，都改成先降四倍，再提两倍  
2. 移除AFF融合四个D的模块，将AFF  
3. 更改为可以融合边缘增强的架构，即解码器中每一层都输出一个结果，然后都计算到损失当中  
4. 解码器引入LSSM，边缘增强分支两个lap+一个差异融合作为分支，融合主干  
5. 修改了损失函数,使用Focal+lovasz
## Version5
1. 模型中的参数量分布不够合理
	1. 对于边缘特征信息，可以使用很少参数量的层来进行特征提取
		1. 但是对于第一个lap，我先直接把两张图片融合6通道直接压成1，毕竟还是两张图像这样一下丢失太多信息了，应该用两个lap对A,B两张图像分别特征提取，然后将两个边缘特征合起来，交给解码层
		2. 解码层，逐像素乘法，大小不一致时，必须有一个为1，因为通过expand把这个1重复，解决方案，使用repeat把lap复制到AB_VSS的大小
	2. 但是对于非浅层的特征不能使用很少参数量的层来处理，会使得特征丢失
2. 归一化使用的理由不够充分
	1. 卷积的偏置只有结合BN时才False
## Version6
修改了vmamba2中的DDB,VSSB2导致其他们版本的VSSM也都跟着变
1. 修改AFF中的tanh激活函数，tanh更适合序列任务，更替为sigmoid更适合图像的二分类任务
	1. 取值0-1，A设定为1-sigmoid，B设定为sigmoid
	2. V5的设计是主干做+1，分支做2-，修改后也保持这个思路，主干不操作，分支做1-，因为重要的还是主干，分支只是做补足
2. 修改编码层的差异提取模块，逐深度卷积改为普通卷积，然后激活从LN改为了BN，这一个改动参数量大很多
3. 调查了一下，没有把数据批数砍掉，所以不存在中间的数据批数很小，所以把除了SSM中的归一，剩下的全部改成BN试一试
4. 高斯卷积不需要偏置项

## Version7
1. 调整损失
	1. 增加解码层输出，即增加out层和损失函数
	2. 在最优的版本上加，如果加上结果更好则保留，反之剔除
	3. 观察一下参数量变化，增加out参数量变化不大，但是Flop增大很多
	4. 损失函数
		1. 二分类更适合二元交叉损失
			1. AERNet，在BCE的基础上增加了两个权重，这个权重由IOU得来，五个SWBCE堆叠得来??
## Version8
1. 先不改损失了
2. 从6.1 BEST 开始改
3. 修改解码器的跳接方式
	1. 没有AFFout时 AB融合
	2. AFFout时，三者融合
	3. 融合完都经过一个convsmall，不再区分有没有AFFout
		1. 融合模块单独拿出来写，因为融合完要给DoG提边缘
		2. SENet
## Version11
1. 